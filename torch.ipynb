{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project of the Mining of Massive Datasets Challenge\n",
    "# Torch and TensorFlow\n",
    "### Micha≈Ç Kempka, Artur Lasowski, Marek Wydmuch\n",
    "#### 2.12.2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'image';\n",
    "torchLogo = image.load('torch.jpg')\n",
    "itorch.image({torchLogo})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lua in 5 minutes or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = 5           -- All numbers are doubles.\n",
    "xStr = 'five'\n",
    "xBool = true\n",
    "\n",
    "local y = 5     -- Variables are global by default. \n",
    "\n",
    "y = nil         -- Undefines t, Lua has garbage collection.\n",
    "\n",
    "function add(a, b)\n",
    "    return a + b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Tables are hash-lookup dictionaries. \n",
    "-- Serve as tables, list, maps, objects and pacakges.\n",
    "-- Indices start at 1.\n",
    "\n",
    "t = { 5, 10, 15, a = 25, b = 30, [xStr] = 5, [x] = xStr, 20 }\n",
    "t.d = 35\n",
    "t['ten'] = 10\n",
    "t[10] = 'ten'\n",
    "\n",
    "function t:add() -- function t.add(self)\n",
    "    return self.a + self.b\n",
    "end\n",
    "\n",
    "t.ab = t:add()   -- t.add(t)\n",
    "  \n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Only nil and false are falsy. 0 and '' are true!\n",
    "x = 0\n",
    "if x then \n",
    "    print('1: ' .. x .. ' is true') \n",
    "end\n",
    "\n",
    "if x ~= 0 then \n",
    "    print('2: ' .. x .. ' is true') \n",
    "end\n",
    "\n",
    "-- Google: Lua in 15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'torch';\n",
    "\n",
    "-- Constructors\n",
    "x = torch.Tensor(3, 5)\n",
    "x:fill(2)\n",
    "x[1][1] = 4\n",
    "x[3][3] = 4\n",
    "\n",
    "y = torch.eye(3, 5) -- rand, ones, zeros, ...\n",
    "\n",
    "xCopy = x:clone() -- z = torch.Tensor(x:size()):copy(x)\n",
    "\n",
    "print('x:')\n",
    "print(x)\n",
    "\n",
    "-- BLAS and element wise\n",
    "z = x * y:t()\n",
    "z:mm(x, y:t()) -- add, dot, ...\n",
    "z:pow(2) -- abs, round, ...\n",
    "\n",
    "print('z: ')\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'cutorch';\n",
    "\n",
    "x = x:cuda()\n",
    "y = y:cuda()\n",
    "xCuda = torch.CudaTensor(3, 5)\n",
    "\n",
    "z:mm(x, y:t()) -- computed on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn';\n",
    "require 'optim';\n",
    "require 'math';\n",
    "\n",
    "-- Load data\n",
    "dofile 'util.lua';\n",
    "\n",
    "datasetSeparable = readFile(\"dataset1\")\n",
    "datasetInseparable = readFile(\"dataset2\")\n",
    "\n",
    "print(datasetSeparable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function splitDataset(dataset, p)\n",
    "    p = p or 0.8\n",
    "    \n",
    "    trainSize = torch.round(dataset.size * p)\n",
    "    testSize = dataset.size - trainSize\n",
    "\n",
    "    train = {\n",
    "        size = trainSize,\n",
    "        data = dataset.data[{{1,trainSize}}]:double(),\n",
    "        label = dataset.label[{{1,trainSize}}]\n",
    "    }\n",
    "\n",
    "    test = {\n",
    "        size = testSize,\n",
    "        data = dataset.data[{{trainSize + 1, trainSize + testSize}}]:double(),\n",
    "        label = dataset.label[{{trainSize + 1, trainSize + testSize}}]\n",
    "    }\n",
    "\n",
    "    return {train=train, test=test}\n",
    "    \n",
    "end\n",
    "\n",
    "_datasetSeparable = splitDataset(datasetSeparable)\n",
    "_datasetInseparable = splitDataset(datasetInseparable)\n",
    "print(_datasetSeparable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Logistic regresion\n",
    "\n",
    "model = nn.Sequential()\n",
    "model:add(nn.Linear(2,1))\n",
    "model:add(nn.Sigmoid())\n",
    "criterion = nn.BCECriterion()\n",
    "\n",
    "x, dldx = model:getParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Some parameters\n",
    "\n",
    "batchSize = 60\n",
    "epochs = 25\n",
    "\n",
    "config = {\n",
    "   learningRate = 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Epoch\n",
    "\n",
    "epoch = function(dataset)\n",
    "    local currentLoss = 0\n",
    "    local count = 0\n",
    "    local shuffle = torch.randperm(dataset.size)\n",
    "    \n",
    "    for d = 1, dataset.size, batchSize do\n",
    "        -- setup inputs and targets for this mini-batch\n",
    "        local size = math.min(d + batchSize - 1, dataset.size) - d\n",
    "        local inputs = torch.Tensor(size, 2)\n",
    "        local targets = torch.Tensor(size)\n",
    "        \n",
    "        for i = 1, size do\n",
    "            local input = dataset.data[shuffle[i + d]]\n",
    "            local target = dataset.label[shuffle[i + d]]\n",
    "            \n",
    "            inputs[i] = input\n",
    "            targets[i] = target\n",
    "        end\n",
    "        \n",
    "        local feval = function(xNew)\n",
    "            -- reset data\n",
    "            if x ~= xNew then x:copy(xNew) end\n",
    "            dldx:zero()\n",
    "\n",
    "            local loss = criterion:forward(model:forward(inputs), targets)\n",
    "            model:backward(inputs, criterion:backward(model.output, targets))\n",
    "\n",
    "            return loss, dldx\n",
    "        end\n",
    "        \n",
    "        _, fs = optim.sgd(feval, x, config)\n",
    "        -- fs is a table containing value of the loss function\n",
    "        -- (just 1 value for the SGD optimization)\n",
    "        count = count + 1\n",
    "        currentLoss = currentLoss + fs[1] -- absence of ++/-- and +=/-= operators\n",
    "    end\n",
    "\n",
    "    -- normalize loss\n",
    "    return currentLoss / count\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Evaluation\n",
    "eval = function(dataset)\n",
    "    local count = 0\n",
    "    \n",
    "    for i = 1, dataset.size, batchSize do\n",
    "        local size = math.min(i + batchSize - 1, dataset.size) - i\n",
    "        local inputs = dataset.data[{{i, i + size - 1}}]\n",
    "        local targets = dataset.label[{{i, i + size - 1}}]\n",
    "        \n",
    "        local outputs = model:forward(inputs)\n",
    "        outputs:round()\n",
    "        local correct = outputs:eq(targets):sum()\n",
    "        count = count + correct\n",
    "    end\n",
    "\n",
    "    return count / dataset.size\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Train\n",
    "function train(dataset, epochs)\n",
    "    epochs = epochs or 1\n",
    "    for i = 1, epochs do\n",
    "        print(string.format('Epoch: %d loss: %3f', i, epoch(dataset.train)))\n",
    "        print(string.format('Train accuracy: %3f', eval(dataset.train)))\n",
    "        print(string.format('Validation accuracy: %3f', eval(dataset.test)))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- FUN\n",
    "torch.manualSeed(9876)\n",
    "model:reset()\n",
    "\n",
    "train(_datasetInseparable, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Saving & Loading models\n",
    "paths = require 'paths'\n",
    "filename = paths.concat(paths.cwd(), 'model.net')\n",
    "\n",
    "torch.save(filename, model)\n",
    "modelLoaded = torch.load(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Simple 3-layer neural network\n",
    "\n",
    "model = nn.Sequential()\n",
    "model:add(nn.Linear(2,10))\n",
    "model:add(nn.ReLU()) -- nn.ReLU\n",
    "model:add(nn.Linear(10,10))\n",
    "model:add(nn.ReLU())\n",
    "model:add(nn.Linear(10,1))\n",
    "model:add(nn.Sigmoid())\n",
    "criterion = nn.BCECriterion()\n",
    "\n",
    "x, dldx = model:getParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- FUN\n",
    "torch.manualSeed(9876)\n",
    "model:reset()\n",
    "\n",
    "train(_datasetInseparable, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass convolution neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = require 'mnist'\n",
    "mnistDataset = mnist.traindataset()\n",
    "\n",
    "itorch.image(mnistDataset.data[{{1, 12}}])\n",
    "print(mnistDataset.label[{{1, 12}}])\n",
    "\n",
    "_mnistDataset = splitDataset(mnistDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model:add(nn.Reshape(28 * 28))\n",
    "model:add(nn.Linear(28 * 28, 30))\n",
    "model:add(nn.Tanh())\n",
    "model:add(nn.Linear(30, 10))\n",
    "model:add(nn.LogSoftMax())\n",
    "criterion = nn.ClassNLLCriterion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- input dimensions\n",
    "nfeats = 3\n",
    "width = 32\n",
    "height = 32\n",
    "ninputs = nfeats*width*height\n",
    "\n",
    "-- number of hidden units (for MLP only):\n",
    "nhiddens = ninputs / 2\n",
    "\n",
    "-- hidden units, filter sizes (for ConvNet only):\n",
    "nstates = {64,64,128}\n",
    "filtsize = 5\n",
    "poolsize = 2\n",
    "\n",
    "-- Typical modern convolution network (conv + relu + pool)\n",
    "\n",
    "model = nn.Sequential()\n",
    "\n",
    "model:add(nn.SpatialConvolutionMM(nfeats, nstates[1], filtsize, filtsize))\n",
    "model:add(nn.ReLU())\n",
    "model:add(nn.SpatialMaxPooling(poolsize,poolsize,poolsize,poolsize))\n",
    "\n",
    "model:add(nn.SpatialConvolutionMM(nstates[1], nstates[2], filtsize, filtsize))\n",
    "model:add(nn.ReLU())\n",
    "model:add(nn.SpatialMaxPooling(poolsize,poolsize,poolsize,poolsize))\n",
    "\n",
    "model:add(nn.View(nstates[2]*filtsize*filtsize))\n",
    "model:add(nn.Dropout(0.5))\n",
    "model:add(nn.Linear(nstates[2]*filtsize*filtsize, nstates[3]))\n",
    "model:add(nn.ReLU())\n",
    "model:add(nn.Linear(nstates[3], noutputs))\n",
    "\n",
    "model:add(nn.Linear(30, 10))\n",
    "model:add(nn.LogSoftMax())\n",
    "\n",
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, dldx = model:getParameters()\n",
    "\n",
    "config = {\n",
    "   learningRate = 1e-2,\n",
    "   learningRateDecay = 1e-4,\n",
    "   weightDecay = 1e-3,\n",
    "   momentum = 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Epoch\n",
    "epoch = function(dataset)\n",
    "    local currentLoss = 0\n",
    "    local count = 0\n",
    "    local shuffle = torch.randperm(dataset.size)\n",
    "    \n",
    "    for d = 1, dataset.size, batchSize do\n",
    "        -- setup inputs and targets for this mini-batch\n",
    "        local size = math.min(d + batchSize - 1, dataset.size) - d\n",
    "        local inputs = torch.Tensor(size, 28, 28) -- HERE!\n",
    "        local targets = torch.Tensor(size)\n",
    "        \n",
    "        for i = 1, size do\n",
    "            local input = dataset.data[shuffle[i + d]]\n",
    "            local target = dataset.label[shuffle[i + d]]\n",
    "            \n",
    "            inputs[i] = input\n",
    "            targets[i] = target\n",
    "        end\n",
    "        targets:add(1)\n",
    "        \n",
    "        local feval = function(xNew)\n",
    "            if x ~= xNew then x:copy(xNew) end\n",
    "            dldx:zero()\n",
    "\n",
    "            local loss = criterion:forward(model:forward(inputs), targets)\n",
    "            model:backward(inputs, criterion:backward(model.output, targets))\n",
    "\n",
    "            return loss, dldx\n",
    "        end\n",
    "        \n",
    "        _, fs = optim.sgd(feval, x, config)\n",
    "        count = count + 1\n",
    "        currentLoss = currentLoss + fs[1]\n",
    "    end\n",
    "\n",
    "    -- normalize loss\n",
    "    return currentLoss / count\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval = function(dataset)\n",
    "    local count = 0\n",
    "    \n",
    "    for i = 1, dataset.size, batchSize do\n",
    "        local size = math.min(i + batchSize - 1, dataset.size) - i\n",
    "        local inputs = dataset.data[{{i, i + size - 1}}]\n",
    "        local targets = dataset.label[{{i, i + size - 1}}]:long()\n",
    "        \n",
    "        local outputs = model:forward(inputs)\n",
    "        local _, outputs = torch.max(outputs, 2)\n",
    "        outputs:add(-1)\n",
    "        \n",
    "        local correct = outputs:eq(targets):sum()\n",
    "        count = count + correct\n",
    "    end\n",
    "\n",
    "    return count / dataset.size\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- FUN\n",
    "torch.manualSeed(9876)\n",
    "model:reset()\n",
    "\n",
    "train(_mnistDataset, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
